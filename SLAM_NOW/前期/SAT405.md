

Is the problem stated both in a general and in a specific way?
Are the purpose and rationale of the project stated clearly?
Are the project aims and objectives clearly stated?
Has a detailed project timeline bee provided (Gantt Chart?)
Have clear outcomes been described and are these realistic?

# Abstract

Simultaneous Localization and Mapping (SLAM)是智能机器人系统的核心技术，亦为智能机器人自主运动的基石。近年来，学者们在视觉和激光雷达 (lidar) SLAM领域取得了突破性进展，然而，由于单一传感器硬件的局限性和技术障碍，仍存在一些挑战。例如，惯性测量单元 (IMU) 的噪声和相机受光照影响的问题。雷达SLAM的定位能够辅助视觉系统在复杂环境中实现精准定位，而视觉系统则可以在纹理丰富的动态环境中稳定工作。相较于传统卡尔曼滤波SLAM框架，紧耦合多传感器融合系统的应用使得构建的地图边缘更清晰，噪声更低，扩大了视觉观测范围并提高了系统的鲁棒性。因此，本文旨在提出一种优化的雷达-视觉-惯性融合框架，以提高智能机器人对环境的感知鲁棒性和准确性，同时保持实时性。

## Problem Statement

背景和问题描述

为了在未知环境中进行感知，移动机器人需要定位自身在地图中的位置和构建环境地图。借助已有的硬件传感器，移动机器人可以捕捉空间信号，构建增量式地图。SLAM 最早是由Smith 和Cheeseman于1986 提出[1]，发展至今已有30 多年。在发展的初期，科学家更加关注SLAM的概率解释，包括扩展卡尔曼滤波器，Rao-Blackwellized粒子滤波器，以及极大似然估计。通过这些数学逻辑来提高计算效率和进行鲁棒数据关联。随着前沿技术的创新和高性能芯片计算发展，SLAM研究被应用在更多复杂场景，努力提高算法的普适性和准确性。

根据使用的传感器类别不同，当前主流的SLAM 系统主要分为激光雷达SLAM、视觉SLAM 以及各类传感器辅助激光/视觉的多传感器融合SLAM 技术。他们各有特点和优劣，其中，视觉SLAM 以相机为基础传感器，能够捕捉大量的图像数据，并且具有实时性，低成本的特点。但是，由于相机对于光线极度敏感的缺陷，如果存在动态物体，地图构建会积累误差导致tracking lost。因为对物体的直接测距，激光雷达slam可以很好解决上述问题，生成更加高精度的地图。此外，激光雷达在复杂场景中容易失效，例如长隧道类走廊、单一墙壁，玻璃镜面等。激光雷达SLAM仅能够重建环境的几何结构，但是缺少颜色信息。

融合激光雷达和相机测量数据的SLAM技术能够克服传感器在定位中的退化问题，生成既精确又纹理丰富的高分辨率三维地图，满足各种建图应用的需求。近年来，很多研究为移动机器人在复杂环境中的定位和感知提供了新的思路和解决方案。



LVI-SAM, FASTLIO2, R3Live++ , fusion SLAM



## Aims and Objective

针对移动机器人在现实复杂环境中精准定位和导航的实际难题，本课题研究多种传感器融合相互辅助提高机器人SLAM的精确性和鲁棒性。实验选择xx模型作为base model，加入辅助模块帮助进行特征提取，优化前端的信息数据分析，与其他几种经典的融合模型进行对比实验。

更多细节如下所示：

1. 搭建移动机器人的硬件和仿真Ubuntu20.04环境，收集SLAM开源数据集，复现经典的LVI-SAM, FASTLIO2, R3Live++ , fusion SLAM，SLAM框架
2. 对模型增加辅助模块，帮助框架进行前端数据处理和特征提取，消除信息噪声，专注于目标特征，更好地是实现多传感器的耦合连接
3. 为了验证模型的可扩展性和鲁棒性，实验将会设计对比和消融实验。
4. 针对稀疏点云地图，实验将会建立三维稠密点云地图，增强框架结果的可视化。

## Project Plan and Expected Outcomes









https://zhuanlan.zhihu.com/p/596228149

https://kns.cnki.net/kns8s/defaultresult/index?crossids=YSTT4HG0%2CLSTPFY1C%2CJUP3MUPD%2CMPMFIG1A%2CWQ0UVIAA%2CBLZOG7CK%2CEMRPGLPA%2CPWFIRAGL%2CNLBO1Z6R%2CNN3FJMUV&korder=SU&kw=%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%20slam

https://blog.csdn.net/xhtchina/article/details/132769377

https://www.guyuehome.com/38613

https://zhuanlan.zhihu.com/p/596228149

经典模型：**EMV-LIO，LVI-SAM, FASTLIO2, R3Live++ , fusion SLAM**

其次，研究了SLAM 激光里程计算法，实现了移动机器人的位姿估计和子图构建。采用IMU 数据对激光点云进行畸变矫正；使用差速驱动机器人的位姿估计算法对机器人位姿进行估计，并为帧与图扫描匹配算法提供初值；通过启发式方法实现了关键帧的选取，根据选取的关键帧进行子图构建；采用Magazino 数据集，分别验证了激光里程计和差速驱动机器人位姿估计算法的有效性。

EMV-LIO: An Efficient Multiple Vision aided LiDAR-Inertial Odometry

https://arxiv.org/abs/2302.00216

https://github.com/BingqiShen/EMV-LIO?tab=readme-ov-file

为了解决单传感器不完全约束所导致的退化问题，近年来，多传感器融合策略，尤其是在激光雷达-视觉-惯性融合领域，引起了业界和研究界的极大兴趣。考虑到单目相机易受某一方向环境光的影响而失效，从而使系统退化为激光雷达-惯性系统，因此引入多目相机来扩大视觉观测范围，以提高系统的精度和鲁棒性。此外，我们还引入了通过测距图像去除激光雷达噪声、设置近邻搜索条件以及用 ikd-Tree 代替 kd-Tree 等方法来提高效率。在此基础上，我们提出了一种高效的多重视觉辅助激光雷达-惯性里程测量系统（EMV-LIO），并在开放数据集和我们定制的数据集上对其性能进行了评估。实验表明，与 LVI-SAM 相比，该算法有助于提高整个系统的精度、鲁棒性和效率。我们的实施方案将在验收后公布。





https://kns.cnki.net/kcms2/article/abstract?v=M7N75Hb03FVN8rhOSQRrId7pJjc7uQiB2O_aAne0hmxHbHXqU-nYXjbHk3aUMg0BqLyY9C8B8y1f2NBZsH9fM1lZMvb1AsUEbICr7fLXyktiCnrQMxOs4nIa9hcMnjSi&uniplatform=NZKPT&language=gb

https://www.cnblogs.com/YongQiVisionIMAX/category/1818560.html

https://kns.cnki.net/kcms2/article/abstract?v=M7N75Hb03FXCGITXQ1-Y1VrKyCsEPu9Qvp436drqZ3oT5u-3P3_9iQLUc0Uc7ZLiwPL97zPfPLRtGpOAHWjTVmXT4lHYivkISx6cwETEAFcVwApjb_H5fA==&uniplatform=NZKPT&language=gb

https://kns.cnki.net/kcms2/article/abstract?v=M7N75Hb03FX7yD8qWrK91EokSLYT5aqHo7kdwMhfAoQ4u0rLAD8vx62VftnfR6yDANJmuypKlU7W1L67dMAjg4_6GsHCOhUorszaekc7xnd44gxt3KQZCY-XLQXuIrgxSIuxJp6XLfEpsMuMr_3Qag==&uniplatform=NZKPT&language=CHS

https://kns.cnki.net/kcms2/article/abstract?v=M7N75Hb03FW81v6ZgQAaeyMRkvGzUwfRvAlSoKdV-ed5hiAmhAhcJddwQmaCh--IBM_m-KLeiytg08cpJ5-_Hxj1Q76QtOZLSwXj4KYn3y2fGAhrRhV9eEw7GvaI47sN7uqaWZDmsYw=&uniplatform=NZKPT&language=CHS

https://arxiv.org/abs/2302.00216

https://xuwuzhou.top/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB18/



